{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30295b4b",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/niteshjindal170988/unsupervised-learning/blob/main/clustering/k_means_clustering.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d447e85",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d5d1cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import warnings\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.datasets import make_blobs\n",
    "import os\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433ee1e9",
   "metadata": {},
   "source": [
    "In this exercise, we will examine Principal Component Analysis and will apply it on  [Digit Recognizer Dataset](https://www.kaggle.com/c/digit-recognizer) tp generate top-30 projections that captures the maximum variance from data.<br>\n",
    "Then, we will apply K-means Clustering on the projected data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6bd85c",
   "metadata": {},
   "source": [
    "# PCA on the Digit-Recognizer Data\n",
    "\n",
    "## Download Dataset from Google Drive\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7143b2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown==4.2.0 in c:\\users\\ag89382\\appdata\\local\\programs\\python\\python37\\deepenv\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ag89382\\appdata\\local\\programs\\python\\python37\\deepenv\\lib\\site-packages (from gdown==4.2.0) (3.6.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ag89382\\appdata\\local\\programs\\python\\python37\\deepenv\\lib\\site-packages (from gdown==4.2.0) (4.62.0)\n",
      "Requirement already satisfied: six in c:\\users\\ag89382\\appdata\\local\\programs\\python\\python37\\deepenv\\lib\\site-packages (from gdown==4.2.0) (1.16.0)\n",
      "Requirement already satisfied: requests[socks] in c:\\users\\ag89382\\appdata\\local\\programs\\python\\python37\\deepenv\\lib\\site-packages (from gdown==4.2.0) (2.26.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\ag89382\\appdata\\local\\programs\\python\\python37\\deepenv\\lib\\site-packages (from gdown==4.2.0) (4.8.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\ag89382\\appdata\\local\\programs\\python\\python37\\deepenv\\lib\\site-packages (from beautifulsoup4->gdown==4.2.0) (2.2.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ag89382\\appdata\\local\\programs\\python\\python37\\deepenv\\lib\\site-packages (from requests[socks]->gdown==4.2.0) (1.26.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ag89382\\appdata\\local\\programs\\python\\python37\\deepenv\\lib\\site-packages (from requests[socks]->gdown==4.2.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ag89382\\appdata\\local\\programs\\python\\python37\\deepenv\\lib\\site-packages (from requests[socks]->gdown==4.2.0) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ag89382\\appdata\\local\\programs\\python\\python37\\deepenv\\lib\\site-packages (from requests[socks]->gdown==4.2.0) (2021.5.30)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in c:\\users\\ag89382\\appdata\\local\\programs\\python\\python37\\deepenv\\lib\\site-packages (from requests[socks]->gdown==4.2.0) (1.7.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\ag89382\\appdata\\local\\programs\\python\\python37\\deepenv\\lib\\site-packages (from tqdm->gdown==4.2.0) (0.4.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.2; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'c:\\users\\ag89382\\appdata\\local\\programs\\python\\python37\\deepenv\\scripts\\python.exe -m pip install --upgrade pip' command.\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1SfSO5ZloHH3W6GJa5rfy9-qwjG4YPbM4\n",
      "To: C:\\Users\\AG89382\\AppData\\Local\\Programs\\Python\\Python37\\deepenv\\tutorials\\unsupervised-learning\\clustering\\train.csv\n",
      "  7%|█████▎                                                                        | 5.24M/76.8M [00:13<02:34, 464kB/s]"
     ]
    }
   ],
   "source": [
    "!pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org gdown==4.2.0\n",
    "import gdown\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Load digit-recognizer (Train Data)\n",
    "url = 'https://drive.google.com/uc?id=1SfSO5ZloHH3W6GJa5rfy9-qwjG4YPbM4'\n",
    "output = 'train.csv'\n",
    "gdown.download(url, output, quiet=False, verify=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ef46e3",
   "metadata": {},
   "source": [
    "# Read Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2adc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train.csv\")\n",
    "display(data.head()) #  Digits / Pixel data\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72d570d",
   "metadata": {},
   "source": [
    "The data set-`train.csv` has 785 columns. The first column, called `label`, which is the digit that was drawn by the user. The rest of the columns contain the pixel-values of the associated image.\n",
    "There are 10 labels (0 to 9).\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3a60bb",
   "metadata": {},
   "source": [
    "# Define a Class PCA to get the Projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259fb21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    #lbl_col_index=0 # global variable ; column index/position having class labels.\n",
    "    def __init__(self, df, lbl_col_index=0):\n",
    "    \n",
    "        '''\n",
    "        Declare instance variables\n",
    "        '''\n",
    "        self.df=df  \n",
    "        self.lbl_col_ind=lbl_col_index\n",
    "        self.labels = pd.Series(self.df.iloc[:,self.lbl_col_ind]).unique() #unique target labels \n",
    "#         print(self.labels)\n",
    "    \n",
    "    def drop_target_column(self, dataframe):\n",
    "        features= dataframe.drop(dataframe.iloc[:,self.lbl_col_ind:self.lbl_col_ind+1], axis=1)\n",
    "        return features\n",
    "            \n",
    "        \n",
    "    def subset_data(self, uniq_trgt_lbl:int):\n",
    "        \n",
    "        '''\n",
    "        Takes an integer value as an input (numeric category label).\n",
    "        Returns-\n",
    "        (1) Pandas Dataframe which is scaled subset of data without labels \n",
    "        (2) Pandas Series of Labels \n",
    "        Standard Scaler returns values with zero mean and unit variance.\n",
    "        '''\n",
    "        subdf=self.df[self.df.iloc[:,self.lbl_col_ind] == self.labels[uniq_trgt_lbl]]\n",
    "        catg = subdf.iloc[:,self.lbl_col_ind]\n",
    "        features = self.drop_target_column(subdf)\n",
    "        return features, catg\n",
    "    \n",
    "    \n",
    "    def feature_scaling(self, features):\n",
    "        scaled_features=StandardScaler(copy=True, with_mean=True).fit_transform(features)\n",
    "        return scaled_features\n",
    "        \n",
    "        \n",
    "    def cov_mat(self, uniq_trgt_lbl: int=None):\n",
    "        '''\n",
    "        Takes in the unique target label to filter the data.\n",
    "        Returns the scaled data of dimensions (4132, 784) \n",
    "        and the covariance matrix of scaled data of dimensions (784, 784).\n",
    "        '''\n",
    "        if uniq_trgt_lbl is None:\n",
    "            subdf=self.drop_target_column(self.df)\n",
    "            scaled_feat=self.feature_scaling(subdf)\n",
    "            covmat = np.cov(scaled_feat, rowvar = False, bias = False)\n",
    "            return scaled_feat, covmat\n",
    "        else:\n",
    "            subdf=self.subset_data(uniq_trgt_lbl)[0] #get the scaled features \n",
    "            scaled_feat=self.feature_scaling(subdf)\n",
    "            covmat = np.cov(scaled_feat, rowvar = False, bias = False)\n",
    "            return scaled_feat, covmat\n",
    "         \n",
    "\n",
    "    def eig_val_eig_vec(self, covariance_matrix):\n",
    "        \n",
    "        '''\n",
    "        Takes input as square array / covariance matrix\n",
    "        and returns pairs of eigen value and eigen vector of the\n",
    "        covariance matrix in descending value of eigen value.\n",
    "        '''\n",
    "        \n",
    "        eigval, eigvec = np.linalg.eig(covariance_matrix)\n",
    "        pairs_eigval_eigvec = [(np.abs(eigval[k]), eigvec[:,k]) for k in range(len(eigval))]\n",
    "        sorted_eg_ev_pairs = sorted(pairs_eigval_eigvec, key=lambda rw: rw[0], reverse=True)  \n",
    "        return sorted_eg_ev_pairs \n",
    "    \n",
    "    def visualize_explained_variance(self, covariance_matrix):\n",
    "        information=self.eig_val_eig_vec(covariance_matrix)\n",
    "        eigval= [i[0] for i in information] #array containing eigen values sorted in descending order\n",
    "        var_exp = [(i/sum(eigval)) for i in eigval] \n",
    "        cum_sum_exp = np.cumsum(var_exp) #cummulative explained variance \n",
    "    \n",
    "        plt.step(range(0,len(cum_sum_exp)),\n",
    "                 cum_sum_exp,\n",
    "                 where='mid',\n",
    "                 label='Cumulative explained variance')\n",
    "        \n",
    "        plt.ylabel('Explained variance ratio')\n",
    "        plt.xlabel('Principal component index')\n",
    "        plt.legend(loc='best')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    def extract_n_principal_components(self, covariance_matrix, reqno_of_pcs):\n",
    "        \n",
    "        '''\n",
    "        Horizontally stacks the top two eigen vectors ordered based on\n",
    "        descending eigen values\n",
    "        '''\n",
    "            \n",
    "        srtd_eg_ev_pair = self.eig_val_eig_vec(covariance_matrix)\n",
    "        stacked_cmpnts=[np.hstack((k[1].reshape(784,1))) for k in srtd_eg_ev_pair[0:reqno_of_pcs]]\n",
    "        stacked_arr=np.asarray(stacked_cmpnts).T\n",
    "        return stacked_arr\n",
    "    \n",
    "    def get_projected_data(self, scaleddata, covariance_matrix, reqno_of_pcs):\n",
    "        '''\n",
    "        Takes the covariance matrix of dimensions D*D \n",
    "        Computes the Dot Product of scaled data for cat0 -> (4132*784)\n",
    "        with the eigen vectors of Covariance Matrix  with highest eigen values (784*2)\n",
    "        Return the projected data set of dimensions (m*2) for example for cat0->(4132*2)\n",
    "        '''\n",
    "        stcked_cmpnts = self.extract_n_principal_components(covariance_matrix, reqno_of_pcs)\n",
    "        projecteddata_nd = scaleddata.dot(stcked_cmpnts)\n",
    "        projecteddata=pd.DataFrame(projecteddata_nd)\n",
    "        projecteddata.columns = [\"PC_\" + str(col) for col in projecteddata.columns]\n",
    "        return projecteddata\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147da932",
   "metadata": {},
   "source": [
    "# Extract the Top-30 Principal Components "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daddfa73",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_categories=sorted(data.label.unique())\n",
    "\n",
    "#create PCA instance (object)\n",
    "pca_instance=PCA(data, 0)  ## 0 is the column index of labels in the data.\n",
    "scaled_dat, covmatr=pca_instance.cov_mat()\n",
    "projecteddata_30d=pca_instance.get_projected_data(scaled_dat, covmatr, 30)\n",
    "projecteddata_30d"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
